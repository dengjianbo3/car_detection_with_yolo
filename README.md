# YOLO V3

几个需要预先知道的知识点：
FCN（fully convolutional network 全卷积神经网络）
    将全连接层换成卷积层，整个网络只有卷积、池化等卷积操作，一般用于目标检测和语义分割任务

upsampling（上采样）
    对通过pooling之后的缩小了的feature map进行反向操作，来扩大feature map的大小，可以通过如反卷积的操作进行完成

YOLO
    yolo只是用了卷积层，是一个FCN形式的网络模型，并且其中没有池化层，75层的卷积操作中，含有跳过连接（如残差块）和上采样层，不使用池化的原因在于防止低级的特征丢失。
    
    一般状况下，卷积层所学习到的特征会被输入到分类/回归器（softmax）来进行预测bounding box或者类别，但是yolo使用的是通过卷积层来完成操作，用来完成分类结果的卷积核尺寸为：
    1 x 1 x （B x （5 + C））
其中B是每个待遇按可以预测的bounding box的数量，5是描述bounding box的5个参数，分别是（x坐标，y坐标，w宽，h高，p目标存在与否），C是表示目标为第C类的置信度（概率），在yolo v3中，B为3，即每个单元格预测3个bounding box，如果检测的对象中心位于单元格的感受野内时候，yolo希望特征图的每个单元格来预测生成一个bounding box来检测对象（尽可能的框住需要检测的对象），为此，一个输入图像需要进行切分，切分的维度应该等于最后特征图的网络维度。
    
    如下面的示意图

    
    图中的是yolo v3的最终特征层结构，一个13*13的网格结构，原图为416*416像素的图像，每个网格的步幅为32，最终的feature map中，每个网格包含着三个bounding box的预测结果，最终所有的参数为13*13*（5+C）*3（如果检测的目标分类为10个的话就是13*13*15*3=7605个参数）。

锚点（anchor box）
    
    如上图所示，每一个网格都会给出3个bounding box来对目标进行检测，具体选哪一个来分配给目标作为真值标签，就需要用到anchor box的概念。
    
    由于实际训练中不稳定的梯度状况，大部分的目标检测器都会在对数空间内进行变化，或者来训练的是预测结果和预选默认bounding box（就是锚点）之间的偏移状况，也就是说对于每一个网格，预先指定好三个不同的锚点框，然后训练的bounding box是相对于这些anchor box的偏移状况，对于上诉的yolo v3来说，因为需要预测3个bounding box，每个网格所对应的anchor box就需要有3个，因为在标注数据上来说本身的边界锚点框就具有最高的IOU，有真值框。

    下面的公式即用来描述网络变换的过程：

    
    中心坐标的预测使用sigmoid函数得到一组0到1之间的输出值，yolo预测的不是确切的中心坐标，而是预测与预测目标的网格单元左上角相关的偏移和使用特征图单元的维度进行归一化的偏移。以上图为例，中心预测为（0.6,0.8），那么假设在单元格左上角坐标为（6,6）（上图红色单元格），那么在该特征图上的中心坐标为（6.6,6.8）。
    但是，如果出现了预测结果大于1，例如（1.7，0.8），那么实际结果的中心坐标就是（7.7,6.8），这样就会打破yolo的基础，该预测中心应该在该单元格内，所以要通过输入sigmoid函数压缩至0—1区间，确保预测中心不会超出该单元格。
    最后通过对输出结果进行对数空间变换，乘以锚点，来预测边界框的维度，得出预测的bw和bh使用图像的高和宽尽心归一化，即预测结果bx，by为（0.3,0.8），则在最终特征图中实际的宽和高为（13*0.3， 13*0.8）。

    objectness分数表示的是目标出现在bounding box中的概率，通过sigmoid函数输出。

    C，类别置信度即每个分类的概率，在v3之前的是使用softmax来进行操作，v3舍弃了softmax层，而是使用sigmoid函数进行分类，原因在于softmax的操作前提是类别本身为互斥，一个检测目标不能包含两种属性，但是一个检测目标同时出现的（dog）和（animal）的检测的话，softmax函数就没有办法区分。

在不同尺度上的预测？？？

    yolo v3在3个不同的尺度上进行预测，检测层在三个不同大小的特征图上执行预测，对弈一个416*416的图像来说，分别进行32,16,8步幅检测的时候，会在13*13,26*26,52*52上的特征图进行检测。
    
    该网络对第一层检测之前对输入图像进行下采样，检测层进行32步幅的特征图进行检测，随后执行2为因子的上采样（反卷积？），并与前一个层的特征图凭借，另一个检测步幅为16的层中进行，重复再进行对8步长的层进行，每个尺度上每个单元使用三个锚点预测三个边框，总共9个锚点。
    
    这样的操作能够帮助yolo v3在检测较小目标时候取得更好的性能，而上采样能帮助网络学习细粒度特征，帮助检测到较小的目标。



输出处理

     总结就是，对于416*416的图像，yolo预测了（52*52+26*26+13*13）×3=10647个bounding boxes，但是图像中明显有许多bounding box是多余的，这个时候就要通过两个手段：设置目标置信度阈值和非极大值抑制来解决。

    设置置信度阈值，就是对objectness分数过滤bounding box，例如当设施阈值为0.5的时候，就会把p值小于0.5的回归向量删除。
    
    非极大值抑制，就是通过对多个bounding box计算和ground truth的IOU值，就是bounding box和ground truth的交集面积除他们的并集面接，留下最大IOU值所代表的一个bounding box。



